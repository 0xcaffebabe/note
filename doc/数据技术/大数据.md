# 大数据

![202171515242](/assets/202171515242.png)

- 数据采集：Flume 、Logstash、Kibana 等
- 数据存储： HBase
- 批处理：Hadoop MapReduce、Spark、Flink 
- 流处理：Storm、Spark Streaming、Flink Streaming

## 计算向存储移动

1. 大规模数据存储在服务器集群的所有服务器上
2. 分布式启动若干任务执行进程
3. 分布式计算编程模型：MapReduce、RDD等，上传代码到各台服务器上
4. 服务器执行代码，代码读取数据进行分布式计算与合并结果

## 特点

4V：

- Volume 大量
- Velocity 高速
- Variety 多样
- Value 低价值密度

## 大数据生态体系

![屏幕截图 2021-02-28 151558](/assets/屏幕截图%202021-02-28%20151558.png)

### Hive

![202171610648](/assets/202171610648.png)

它可以将结构化的数据文件映射成表，并提供类 SQL 查询功能，但受限于编程模型，一些诸如嵌套SQL等标准SQL的功能时不支持的

- 离线分析

### Spark

- Spark SQL 主要用于结构化数据的处理：支持以SQL语法查询各种数据源
- Spark Streaming：微批处理 达到类流处理
- MLlib：机器学习库
- Graphx：用于图形计算和图形并行计算的新组件

Spark 比 MapReduce 快的原因：更为简单的 RDD 编程模型减少了作业调度次数，以及优先使用内存

![各组件](/assets/202338213435.webp)

1. SparkContext 启动 DAGScheduler 构造执行的 DAG 图，拆分成计算任务
2. Driver 向 Cluster Manager 请求计算资源，分配 Worker
3. Worker 向 Driver 注册并下载代码执行

### Storm

- 实时流处理

### Flink

- 分布式的流处理框架，它能够对有界和无界的数据流进行高效的处理

### Hbase

- 构建在 Hadoop 文件系统之上的面向列的数据库管理系统

![架构](/assets/202338214430.webp)

HRegion 是负责数据存储的主要进程，每个 HRegionServer 上可以启动多个 HRegion 实例，当一个 HRegion 中写入的数据太多，一个 HRegion 会分裂成两个，进行负载迁移

```mermaid
sequenceDiagram
  应用程序 ->> ZK: 请求HMaster地址
  应用程序 ->> HMaster: 输入key，请求HRegionServer地址
  应用程序 ->> HRegionServer: 输入key，查询数据
  HRegionServer ->> HRegion: 访问实例获取数据
```

Phoenix：HBase 的开源 SQL 中间层

### Flume

- 数据收集系统，通常用于日志数据的收集

![2021719142122](/assets/2021719142122.png)
