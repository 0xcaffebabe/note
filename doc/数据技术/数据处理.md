---
tags: ['数据处理', '计算模型', '数据架构', '流处理', '批处理']
---

# 数据处理

## 一、第一性原理：数据处理系统究竟在解决什么问题

从抽象层面看，**所有数据处理系统都在回答同一个问题**：

> 如何在可控成本下，把原始数据持续、可靠、可解释地转化为可消费的信息。

拆解后，本质只有三类不可回避的矛盾：

1. **时效性 vs 准确性**：结果要快，还是要准？
2. **表达能力 vs 系统复杂度**：计算模型越强，系统越复杂
3. **工程效率 vs 运维成本**：越“自动化”，越依赖底层系统能力

后续所有计算引擎、架构范式、API 设计，本质都是在这三组张力之间取不同的平衡点。

---

## 二、计算引擎选型的三维空间（统一抽象）

### 1. 响应速度：时间维度上的分层

响应速度不是“快或慢”的问题，而是**数据是否有界**的问题：

* **实时计算（毫秒级）**：无界数据 + 增量更新
* **交互式分析（秒级）**：近实时 + 强索引
* **批处理（分钟~小时）**：有界数据 + 全量或准全量计算

> 本质区别：是否允许“等待完整数据集”。

---

### 2. 灵活性：计算模型的表达上限

灵活性来自三个正交维度：

* **计算范式**：SQL → 窗口 → 状态 → ML / 图
* **数据模型**：结构化 → 半结构化 → 无结构
* **扩展机制**：UDF / 插件 / API

> 表达能力越强，对执行引擎的约束和状态管理要求越高。

---

### 3. 使用难度：系统复杂度的外溢程度

使用难度不是“是否有 SQL”，而是复杂性是否被**系统内部吸收**：

* 学习成本：是否符合用户心智模型
* 开发效率：是否减少重复表达
* 运维门槛：是否将失败、扩容、调优变成“默认能力”

---

## 三、数据处理的基本计算模型

### 1. 批处理模型

**定义**：

* 输入数据有界、不可变
* 计算过程无副作用
* 结果可重放、可验证

UNIX Pipeline、MapReduce 都属于这一范畴。

#### MapReduce 的本质缺陷

并非“慢”，而是：

* 抽象层次过低（计算细节外泄）
* shuffle 成本显性暴露
* 异常处理与业务逻辑强耦合

> 它暴露的是“分布式计算的真实复杂度”，而不是业务模型。

---

### 2. 流处理模型

**核心假设改变**：

* 数据无界
* 结果只能通过增量逼近
* 状态是第一等公民

> 一旦承认数据无界，时间就成为必须显式建模的维度。

---

## 四、统一抽象：DAG 作为计算的通用表示

无论批处理还是流处理，最终都会被编译为 **有向无环图（DAG）**：

* 节点：计算算子
* 边：数据依赖

### DAG 的两种形态

#### 1. 单任务 DAG

* 内存中完成
* shuffle 为阶段边界
* Spark 的 Stage 模型

#### 2. 管道 DAG

* 以存储作为阶段隔离
* 强一致性与数据复用
* 典型于 ETL 工作流

> DAG 的价值在于：**让系统有机会做全局优化**。

---

## 五、架构范式：如何组织批与流

### 1. Lambda 架构

**核心思想**：

* 批处理保证最终正确性
* 流处理保证时效性
* 查询层做结果合并

**致命问题**：

* 两套计算逻辑
* 两套状态语义
* 一致性只能事后修复

---

### 2. Kappa 架构

**关键前提**：

* 一个可回放的日志系统
* 所有计算都是流式

**优势**：

* 架构极简
* 逻辑唯一

**代价**：

* 历史重算成本极高

---

### 3. 事件溯源

**核心模型**：

* 状态 = 事件序列的函数
* 快照用于压缩历史

**适用场景**：

* 领域驱动设计
* 强审计、强一致性需求

---

## 六、Spark：批处理时代的集大成者

### 设计必然性

Spark 的成功并非偶然，而是精准命中了三点：

1. RDD 把容错内嵌进数据模型
2. DAG Scheduler 吸收执行复杂度
3. 内存优先，磁盘兜底

### Spark SQL 的本质

Catalyst = 关系代数 + 规则引擎 + 代价模型

> SQL 不是接口，而是**可优化的中间表示**。

### Structured Streaming

* 不是“更快的 Spark Streaming”
* 而是 **流处理的关系化表达**

---

## 七、Flink：以流为一等公民

Flink 的核心取舍：

* 状态显式建模
* 事件时间优先
* 精确一次语义

> Flink 不是 Spark 的“流模式”，而是完全不同的计算哲学。

---

## 八、Beam：计算模型的抽象层

Beam 的定位不是引擎，而是：

> 对“分布式数据处理”进行形式化建模。

* PCollection：统一表达有界 / 无界
* Window / Watermark / Trigger：时间语义
* Runner：把模型映射到具体引擎

---

## 九、Streaming SQL：表达力的终极形态

当计算模型稳定后，**最终一定会走向声明式**：

* 用户描述“要什么”
* 系统决定“怎么做”

Streaming SQL 是：

* 关系模型
* 状态机
* 事件模式匹配

的统一外壳。

---

## 总结

1. **先选模型，再选引擎**
2. **复杂性只能被转移，不能被消灭**
3. **能被统一描述的，一定会被统一执行**
4. **所有成功的系统，都在隐藏分布式本质**

## 关联内容（自动生成）

- [/数据技术/流处理.md](/数据技术/流处理.md) 流处理是数据处理的一种重要范式，与批处理共同构成现代数据处理的两大核心模式，两者在架构设计、计算模型和应用场景上各有侧重
- [/数据技术/数据架构.md](/数据技术/数据架构.md) 数据架构为数据处理提供了整体框架和结构化载体，决定了数据流动方式和处理系统的可扩展性，是实现数据处理的技术基础
- [/数据技术/大数据.md](/数据技术/大数据.md) 大数据技术栈是数据处理的重要技术基础，提供了大规模数据处理、存储和传输的能力，支撑企业级数据处理需求
- [/数据技术/数据工程.md](/数据技术/数据工程.md) 数据工程实践需要基于规范的数据处理来组织数据生产流程，数据处理为数据工程提供标准化的数据转换和建模路径
- [/数据技术/数据集成.md](/数据技术/数据集成.md) 数据处理是数据集成的核心环节之一，数据集成的转换与建模层涉及复杂的批处理、流处理和ELT操作，需要依赖各种数据处理引擎和框架
- [/数据技术/数据治理.md](/数据技术/数据治理.md) 数据处理环节需遵循数据治理的质量规范，保证ETL过程中数据质量及降低运维成本，满足治理提出的规则要求
- [/数据技术/数据仓库.md](/数据技术/数据仓库.md) 数据仓库建设涉及大量的数据处理工作，包括ETL流程设计、数据建模和数据分层处理
- [/数据技术/任务调度系统.md](/数据技术/任务调度系统.md) 任务调度系统是数据处理的重要支撑，确保数据处理任务能够按时、准确执行
- [/中间件/消息队列/Kafka/Kafka.md](/中间件/消息队列/Kafka/Kafka.md) Kafka作为流处理架构的核心组件，提供了实时数据流的传输和缓冲能力，是现代数据处理架构的重要基础设施
- [/数据技术/机器学习.md](/数据技术/机器学习.md) 机器学习流程中的数据预处理是数据处理的重要应用领域，数据质量直接影响模型的学习效果和泛化能力

