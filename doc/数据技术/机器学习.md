# 机器学习

频率视角下的机器学习：认为模型待估计的参数是固定不变的常量，用来估计参数的数据是随机的变量，需要我们通过某种手段（比如极大似然法）利用数据找到最优参数，损失函数（loss function）直接定义了模型性能的度量方式，其数学期望被称为风险（risk），风险最小化就是参数估计的依据和准则，用训练数据的经验分布替换掉原始表达式中数据的真实分布，借此找到最优参数

贝叶斯视角下的机器学习：将待估计的参数视为随机变量，用来估计的数据反过来是确定的常数，结合参数自身的分布特性，找到最可能产生观测数据的那个参数的过程，贝叶斯学习的输出是关于参数的概率分布

可被机器学习解决的问题：

1. 解决的问题会包含某些显式或者隐式的模式
2. 无法通过数值计算解决
3. 要有大量的可用数据

- 监督学习：利用样本和期望输出来学习如何预测
- 无监督学习：在一组数据中寻找某种结构

监督学习适用于预测任务，无监督学习适用于描述任务

- 批量学习：一口气对整个数据集进行建模与学习，并得到最佳假设
- 在线学习：算法根据数据的不断馈入而动态地更新
- 主动学习：有选择地询问无标签数据的标签来实现迭代式的学习

计算学习理论：关于通过”计算“来进行学习的理论，即关于机器学习的理论基础
目的：分析学习任务的困难本质，为学习算法提供理论保证，指导算法设计

## 模型

- 参数模型：待求解的概率分布或者数量关系可以用一组有限且固定数目的参数完全刻画，最典型的是线性回归
- 非参数模型：认为存在一个未知的映射 f()˙​，输入通过这个映射转为输出，学习的对象也是这个映射

参数模型与非参数下模型的区别体现的是可解释性和精确性的区别

1. 模型拟合（model fitting）：利用训练数据集（training set）对模型的普通参数进行拟合
2. 模型选择（model selection）：利用验证数据集（validation set）对模型的超参数进行调整，筛选出性能最好的模型
3. 模型评价（model assessment）：利用测试数据集（test set）来估计筛选出的模型在未知数据上的真实性能

偏差的含义是模型预测值的期望和真实结果之间的区别，如果偏差为 0，模型给出的估计的就是无偏估计，方差的含义则是模型预测值的方差，也就是预测值本身的波动程度，方差越小意味着模型越有效。

模型的设计追求低偏差，即准确度高，低方差，即比较简单的模型。即在过拟合与欠拟合直接选择

模型验证的任务就是确定模型的复杂度以避免过拟合的发生，选择数据集基本的原则就是确保训练集、验证集和测试集三者两两互不相交，同时保证三个数据集中正例和负例的比例应该大致一致，避免在数据集之间出现不平衡，再在这些数据集上使用Holdout检验或者交叉校验

## 实验

实验设计的任务是观察一个或多个因子对实验结果的影响，因此包括算法类型、超参数、数据集等

- 一次一因子（控制变量法）：为所有因子都设定一个基线值，再在其他因子保持在基线水平的前提下令单个因子波动，观察它对学习性能的影响
- 全因子实验（full factorial experiment）：每个因子都有有限个离散的取值，实验则覆盖了所有因子所有取值的所有可能组合
- 连续实验（sequential experimentation）：首先执行全因子实验，但只给每个因子赋予较少的可能取值，确定哪些是对学习结果影响较大的活跃因子并保留下来，剩下的不活跃的因子就会被放弃
- 响应面方法（response surface methodology）：通过二次曲面的拟合寻找可变因子的最佳取值

## [特征工程](/数据技术/数据处理.md#特征工程)

异常点会导致数据的有偏分布，如果异常点是由于采集出错，需要剔除这些异常点。如果异常点本身没有问题，除了剔除异常点之外，除了可以对所有特征值采取对数变化降低数值外，还能使用空间标识把异常点拉成正常

对于缺失的特征值，可以用 k 近邻方法和线性回归对特征的缺失值进行人为赋值

如果某个特征在绝大多数数据中的取值都是相同的，那这个特征就没有存在的意义，因为它体现不出对于不同分类结果的区分度，可以把这个特征去掉
