{"name":"数据库优化","id":"中间件-数据库-mysql-数据库优化","content":"# 数据库优化\n\n对于优化最重要的事是测量，如果优化的成本高于收益，就要停止优化。\n\n## 优化原因\n\n- 避免网站出现访问错误\n- 低效的查询导致数据库不稳定\n- 优化用户体验\n\n## 优化方面\n\n- 硬件\n- 系统配置\n- 数据库表结构\n- SQL与索引\n\n成本从下到上递增，效果从上到下递减\n\n## MYSQL优化\n\n### 监控\n\n#### 性能剖析 show profile(逐渐淘汰)\n\n一条SQL语句结束后\n\n使用show profile查询剖析工具，可以指定具体的type\n\n```sh\nshow profile cpu;\n```\n\nall：显示所有性能信息\n\nblock io：显示块io操作的次数\n\ncontext switches：显示上下文切换次数，被动和主动\n\ncpu：显示用户cpu时间、系统cpu时间\n\nIPC：显示发送和接受的消息数量\n\nmemory：内存\n\npage faults：显示页错误数量\n\nsource：显示源码中的函数名称与位置\n\nswaps：显示swap的次数\n\nshow status则可以查看相关计数器数据，计数器数据价值相较于profile低。\n\n#### 使用performance schema\n\n通过该数据库直接通过sql就能得到服务器相关的一些测量信息\n\n#### 使用show processlist查看连接的线程个数\n\n## 开启慢查询\n\n慢查询日志式开销最低，精度最高的测量查询时间的工具\n\n```shell\nset global slow_query_log=ON; #开启慢查询\nset global long_query_time=1.0; #设置记录时长为1秒\nset global log_queries_not_using_indexes = ON; #不适用索引\n```\n\n慢查询日志地址：\n\n地址存储在slow_query_log_file变量中\n\n## 慢查询日志存储格式\n\n```\n# Time: 2019-11-29T06:01:43.909217Z 执行时间\n# User@Host: root[root] @ localhost []  Id:     9 主机信息\n# Query_time: 0.104442 查询时间\n  Lock_time: 0.000153 锁定时间\n   Rows_sent: 1  发送行数\n   Rows_examined: 16249 锁扫描行数\nSET timestamp=1575007303; 执行时间戳\nselect count(*) from actor,payment; SQL\n```\n\n## 慢查询分析工具\n\n- mysqldumpslow\n\n```shell\nmysqldumpslow -t 10 日志地址 # 分析前10条记录\n```\n\n- pt-query-digest\n\n```shell\nwget percona.com/get/pt-query-digest # 下载\nchmod u+x pt-query-digest # 添加执行权限\n/pt-query-digest 慢查询日志地址 # 分析日志\n```\n\n## 问题定位\n\n- 次数多、时间长\n- IO大\n- 未命中索引\n\n## 数据库结构优化\n\n- 选择合适的数据类型\n- 范式化\n- 反范式化\n\n### 垂直拆分\n\nID|Name|Avatar\n-|-|-\n1|Shaun|`<Binaries>`\n2|Lucy|`<Binaries>`\n3|Linda|`<Binaries>`\n4|Mary|`<Binaries>`\n5|Tom|`<Binaries>`\n\n↓\n\nID|Name\n-|-\n1|Shaun\n2|Lucy\n3|Linda\n4|Mary\n5|Tom\n\nAvatar|ID\n-|-\n`<Binaries>`|1\n`<Binaries>`|2\n`<Binaries>`|3\n`<Binaries>`|4\n`<Binaries>`|5\n\n使用垂直切分将按数据库中表的密集程度部署到不同的库中\n\n切分后部分表无法join，只能通过接口方式解决，提高了系统复杂度，存在分布式事务问题\n\n### 水平拆分\n\nID|Name\n-|-\n1|Shaun\n2|Lucy\n3|Linda\n4|Mary\n5|Tom\n\n↓\n\nID|Name\n-|-\n1|Shaun\n2|Lucy\n3|Linda\n\nID|Name\n-|-\n4|Mary\n5|Tom\n\n当一个表的数据不断增多时，水平拆分是必然的选择，它可以将数据分布到集群的不同节点上，从而缓存单个数据库的压力\n\n### 分库分表\n\n同上面的水平拆分，每张表或者每个库只存储一定量的数据，当需要进行数据读写时，根据唯一ID取模得到数据的位置\n\n**为什么分库分表能提高性能**\n\n将一张表的数据拆分成多个n张表进行存放，然后使用第三方中间件（MyCat或者Sharding-JDBC）可以并行查询\n\n**一些分库分表中间件**\n\ncobar，tddl，atlas，**sharing-jdbc**，**my-cat**\n\n#### 系统迁移到分库分表\n\n如何将一个单库单表的系统动态迁移到分库分表上去\n\n- 停机迁移\n\n禁止全部数据写入，编写一个程序，将单库单表的数据写到分库分表上：\n\n1. 应用程序预先实现分库分表的支持\n2. 停机暂停所有流量接入\n3. 启动脚本，循环读取数据，将每一条数据按照既定规则写入到新库，直至完成\n4. 应用程序切换到新库上\n5. 恢复，继续接收流量\n\n- 双写迁移\n\n新系统部署后，每条数据都会在老库和新库写一遍\n\n双写切换流程：\n\n1. 刚开始只读写老库\n2. 切换到读写老库的同时，开始往新库写一遍数据\n3. 切换到只写老库，开始启用新库读写\n4. 完成切换，不再写老库，只用新库读写\n\n同时还需要一个校验与修复脚本持续不断运行，将老库与新库不一致的数据修复，把老库更新到新库的条件是：老库有的数据新库没有，或者是老库的数据更新时间比新库的新\n\n工具会比较新库与老库的每一条数据，只有每条数据都一致，才算完成，否则持续运行校验，这样脚本几轮操作过去后，新老库的数据就一致了\n\n**动态扩容缩容的分库分表方案**\n\n- 停机扩容\n\n同上，只不过上面那是从单个数据库到多个数据库，这次这个是多个数据库到多个数据库\n但是不推荐这种做法，原因是数据量很大，数据很难在短时间内转移完毕\n\n- 第一次分库分表，就一次性给他分个够\n\n32 个库，每个库 32 个表\n这里可以多个库都在同一台机器上，当不够用的时候，可以将这些库转移到新机器上\n这样，数据的逻辑位置没有发生改变，也避免扩容缩容带来的数据迁移问题\n\n- 级联同步迁移\n\n比较适合数据从自建机房向云上迁移的场景，在切写的时候需要短暂的停止写入\n\n![2022816205127](/assets/2022816205127.webp)\n\n#### 唯一ID生成\n\n- 使用一个单点系统来做自增ID的获取\n  - 必须要能应对时钟回拨，或者服务器异常重启之后计数器不会重复的问题\n  - redis、数据库自带的自增\n  - 多个节点的ID获取无法并行\n- 使用多个单点系统，每个系统自增ID设置相同的步长不同的初始值，这样就能保证这些节点ID不会重复\n  - 但这种方式注定了节点数量不能变化\n\n为了避免每次生成都需要一次调用，在需要产生新的全局 ID 的时候，每次单点服务都向数据库批量申请 n 个 ID，在本地用内存维护这个号段，并把数据库中的 ID 修改为当前值 +n，直到这 n 个 ID 被耗尽；下次需要产生新的全局 ID 的时候，再次到数据库申请一段新的号段\n\n- UUID\n  - UUID组成部分:当前日期和时间+时钟序列+随机数+全局唯一的IEEE机器识别号\n  - 比较长，无法保证趋势递增，做索引时查询效率低\n- 系统时间\n  - 可以使用业务字段来拼接避免重复\n- 雪花算法\n  - 一个 64 位的 long 型的 id，第一个 bit 是不用的，用其中的 41 bit 作为毫秒数，用 10 bit 作为工作机器 id，12 bit 作为序列号\n  - 单个节点内无法并行\n  - 多个节点可以并行\n  - 可以支撑每秒400万+的ID生成，在某些实现里，如果某一毫秒内的计数器被耗尽达到上限，会死循环直至这 1ms 过去\n\n### 拆分策略\n\n使用水平拆分时，操作一条数据，要在哪张表找到它\n\n- 哈希取模\n- 范围，ID范围，时间范围\n- 映射表\n\n### 拆分后的问题\n\n- 事务\n  - 使用分布式事务\n- 连接\n  - 原来的连接需要分解成多个单表查询，在应用层进行连接\n- ID唯一性\n  - 全局唯一ID（GUID）\n  - 每个分片指定ID范围\n  - 分布式ID生成器，雪花算法\n\n## 一个查询的执行顺序\n\n```sql\n(8) SELECT (9)DISTINCT<select list>\n(1) FROM <left table>\n(3) <join_type>JOIN<right_table>\n(2) ON<join condition>\n(4) WHERE<where condition>\n(5) GROUP BY<group_by_list>\n(6) WITH (CUBE|ROLLUP)\n(7) HAVING<having condition>\n(10) ORDER BY<order by_list>\n(11) LIMIT <limit number>\n```\n\n1. FORM: 对FROM的左边的表和右边的表计算笛卡尔积。产生虚表VT1\n2. ON: 对虚表VT1进行ON筛选，只有那些符合`<join-condition>`的行才会被记录在虚表VT2中。\n3. JOIN： 如果指定了OUTER JOIN（比如left join、 right join），那么保留表中未匹配的行就会作为外部行添加到虚拟表VT2中，产生虚拟表VT3, rug from子句中包含两个以上的表的话，那么就会对上一个join连接产生的结果VT3和下一个表重复执行步骤1~3这三个步骤，一直到处理完所有的表为止。\n4. WHERE： 对虚拟表VT3进行WHERE条件过滤。只有符合`<where-condition>`的记录才会被插入到虚拟表VT4中。\n5. GROUP BY: 根据group by子句中的列，对VT4中的记录进行分组操作，产生VT5.\n6. CUBE | ROLLUP: 对表VT5进行cube或者rollup操作，产生表VT6.\n- HAVING： 对虚拟表VT6应用having过滤，只有符合`<having-condition>`的记录才会被 插入到虚拟表VT7中。\n7. SELECT： 执行select操作，选择指定的列，插入到虚拟表VT8中。\n8. DISTINCT： 对VT8中的记录进行去重。产生虚拟表VT9.\n9. ORDER BY: 将虚拟表VT9中的记录按照`<order_by_list>`进行排序操作，产生虚拟表VT10.\n10. LIMIT：取出指定行的记录，产生虚拟表VT11, 并将结果返回。\n","metadata":"","hasMoreCommit":true,"totalCommits":22,"commitList":[{"date":"2024-12-11T19:59:57+08:00","author":"MY","message":"📦MySQL","hash":"5c96cf53bb2f2ca8359f5fab16cf12f5ef224bbc"},{"date":"2024-11-07T16:23:04+08:00","author":"MY","message":"📦MySQL","hash":"cc0b244f98955ea55043ef57b13e9fe490a110b1"},{"date":"2024-11-06T19:33:09+08:00","author":"MY","message":"📦MySQL","hash":"8c2a462ec10106b29a91c0b5e99e33ff2dd180b8"},{"date":"2023-03-09T09:41:00Z","author":"My","message":"🛠替换在线图片","hash":"0c8b08bc22fbe482ba02da2f1fcad211441d3c23"},{"date":"2022-08-16T20:53:24+08:00","author":"MY","message":"✏️数据库优化","hash":"3e5eaccfed6b07a4b7ed2f1d5e859f21b2466c51"},{"date":"2022-07-11T15:08:47+08:00","author":"cjiping","message":"✏️更新 分布式算法","hash":"724e42379b37f932d2d165bef4d67df2be095cb4"},{"date":"2021-12-26T19:26:35+08:00","author":"MY","message":"✏️更新 数据库迁移","hash":"73ed1ec1c933e46c083ff34e80d8ec04830dedbf"},{"date":"2021-03-02T18:20:39+08:00","author":"cjiping","message":"✏更新 MySQL 优化","hash":"1966127b63a695eadb4f5042ee7cba5981012756"},{"date":"2021-03-01T17:34:38+08:00","author":"cjiping","message":"✏更新 MySQL 数据库优化","hash":"af2b5a2bb8a5d739e7a210730abc3b17ee3414bd"},{"date":"2020-08-24T15:34:56+08:00","author":"MY","message":"✏更新 mysql","hash":"b94b9491ad96394d389cf8b9e510fbc6a63a2644"}],"createTime":"2019-11-25T22:30:55+08:00"}