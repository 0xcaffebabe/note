{"name":"生产者","id":"中间件-消息队列-Kafka-生产者","content":"# 生产者\n\n![屏幕截图 2020-08-20 150154](/assets/屏幕截图%202020-08-20%20150154.png)\n\n发送消息：\n\n```java\nProperties props = new Properties();\n//kafka 集群，broker-list\nprops.put(\"bootstrap.servers\", \"172.24.211.140:9092\");\nprops.put(\"key.serializer\",\n        \"org.apache.kafka.common.serialization.StringSerializer\");\nprops.put(\"value.serializer\",\n        \"org.apache.kafka.common.serialization.StringSerializer\");\nProducer<String,  String> producer  =  new\n        KafkaProducer<>(props);\nfor (int i = 0; i < 10; i++) {\n    var record =\n            new ProducerRecord<>(\"test\", \"Precision Products\",\n                    \"France\");\n    producer.send(record, new Callback() {\n        @Override\n        public void onCompletion(RecordMetadata metadata, Exception exception) {\n            System.out.println(metadata);\n        }\n    });\n\n}\nproducer.close();\n```\n\n## 配置\n\n- acks\n  - 定了必须要有多少个分区副本收到消息，生产者才会认为消息写入是成功的 \n  - acks=0 ，生产者在成功写入消息之前不会等待任何来自服务器的响应 当 broker 故障时有可能 丢失数据\n  - acks=1 ，只要集群的首领节点收到消息，生产者就会收到一个来自服务器的成功响应 如果在 follower同步成功之前 leader 故障，那么将会丢失数据\n  - acks=all ，只有当所有参与复制的节点全部收到消息时，生产者才会收到一个来自服务器的成功响应 如果在 follower 同步完成后，broker 发送 ack 之前，leader 发生故障，那么会造成 数据重复\n- buffer.memory\n  - 设置生产者内存缓冲区的大小\n- compression.type\n   - 设置消息压缩算法\n- retries\n  - 决定了生产者可以重发消息的次数，如果达到这个次数，生产者会放弃重试并返回错误\n- batch.size\n  - 指定了一个批次可以使用的内存大小\n- linger.ms\n  -  KafkaProducer 会在批次填满或 linger.ms 达到上限时把批次发送出去。默认情况下，只要有可用的线程，生产者就会把消息发送出去\n- client.id\n- max.in.flight.requests.per.connection\n  - 指定了生产者在收到服务器响应之前可以发送多少个消息\n-  timeout.ms、request.timeout.ms 和 metadata.fetch.timeout.ms\n-  max.block.ms\n   - 调用send时最长的阻塞时间\n - max.request.siz\n - receive.buffer.bytes 和 send.buffer.bytes\n   - 分别指定了 TCP socket 接收和发送数据包的缓冲区大小\n\n**顺序保证**\n\n- 将max.in.flight.requests.per.connection设置为1\n\n![屏幕截图 2020-08-24 085111](/assets/屏幕截图%202020-08-24%20085111.png)\n\n保证顺序的方法就是：\n\n1. 每个主题只分为一个区\n2. 或者每次发送的消息发送到同一个分区\n\n## 序列化器\n\n- 自定义序列化器：实现`Serializer`接口\n  - 不推荐使用\n- 其他序列化\n  - avro：一种将shcema嵌入在数据里的序列化方式\n\n## 分区策略\n\n分区的原因：\n\n- 方便扩展\n- 提高并发\n\n分区原则：\n\n- 指明 partition 的情况下，直接将指明的值直接作为 partiton 值\n- 没有指明 partition 值但有 key 的情况下，将 key 的 hash 值与 topic 的 partition数进行取余得到 partition 值\n- 否则就是随机取一个值 然后在这个值的基础上进行轮询\n\n自定义分区器：\n\n实现`Partitioner`接口\n\n## 数据可靠性保证\n\n- Exactly Once\n\n将服务器的 ACK 级别设置为-1，可以保证 Producer 到 Server 之间不会丢失数据，即 AtLeast Once 语义\n\nAt Least Once + 幂等性 = Exactly Once\n\n另外一个需要注意的是要注册发送回调，发生不成功，需要客户端进行重试\n\n## 生产者幂等\n\n生产者可以指定 enable.idempotence 来实现生产幂等，其原理是 broker 引入了ProducerID和SequenceNumber，每个新的Producer初始化时，会被分配一个唯一的ProducerID，同时生产者为每条消息生成SequenceNumber，broker 端通过这两个字段来判断数据之前是否发送过，从而实现幂等\n\n这种幂等判断只能保证某个主题的一个分区上不出现重复消息\n\n## 事务\n\n能保证多条消息原子性地写入到目标分区，同时也能保证 Consumer 只能看到事务成功提交的消息\n\n```java\nproducer.beginTransaction(); \nproducer.send(record1); \nproducer.send(record2); \nproducer.commitTransaction();\n```\n\n是一种类似 [2PC](/软件工程/架构/系统设计/分布式/分布式事务.md) 的实现\n","metadata":"","hasMoreCommit":false,"totalCommits":3,"commitList":[{"date":"2024-11-20T16:12:20+08:00","author":"MY","message":"📦Kafka","hash":"955524f9775b97e250675e61652f914ad8337055"},{"date":"2023-11-27T19:34:35+08:00","author":"MY","message":"✏Kafka","hash":"024a5acdd5f2fe23e8806d9565e8a049ce161629"},{"date":"2021-04-06T10:18:12+08:00","author":"cjiping","message":"📦整理 Kafka 生产者","hash":"5799f4cb9ea20597008aabaf8063c3402388378c"}],"createTime":"2021-04-06T10:18:12+08:00"}