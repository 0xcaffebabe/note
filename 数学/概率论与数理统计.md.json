{"name":"概率论与数理统计","id":"数学-概率论与数理统计","content":"# 概率论与数理统计\n\n概率（Probability）：描述事件发生的可能性的一个数值\n\n概率和统计其实是互逆的，概率论是对数据产生的过程进行建模，然后研究某种模型所产生的数据有什么特性。而统计学正好相反，它需要通过已知的数据，来推导产生这些数据的模型是怎样的\n\n## 随机事件\n\n### 样本空间和随机事件\n\n- 随机试验\n  - 可在相同条件下重复进行（可重复性）\n  - 全部结果是已知的（结果已知性）\n  - 事前无法预知结果（不可预测性）\n- 随机事件\n  - 在随机试验中，对某些现象的陈述\n  - 必然事件Ω\n  - 不可能事件∅\n  - 基本事件：一次试验中必发生且最简单的事件\n  - 复合事件：若干基本事件组成\n- 样本空间\n  - 样本点：试验的每一个可能结果\n  - 样本点全体称为样本空间\n\n### 事件关系和运算\n\n- 包含\n  - A发生必然导致B发生\n  - A ⊂ B\n  - 如果 A ⊂ B 且 B ⊂ A,则 A = B\n- 和(并)事件\n  - A ∪ B\n- 积(交)事件\n  - A ∩ B 或者 AB\n- 互不相容(互斥)\n  - 事件A,B不可能在一次试验同时发生\n- 对立事件(逆事件)\n  - B = {A不发生}\n  - B = <SPAN style=\"TEXT-DECORATION: overline\">A</SPAN>\n- 差事件\n  - A-B 或 A<SPAN style=\"TEXT-DECORATION: overline\">B</SPAN>\n\n运算律\n\n交换律：\n\\[\nA \\cup B = B \\cup A, \\quad A \\cap B = B \\cap A\n\\]\n\n结合律：\n\\[\n(A \\cup B) \\cup C = A \\cup (B \\cup C), \\quad (A \\cap B) \\cap C = A \\cap (B \\cap C)\n\\]\n\n分配律：\n\\[\n(A \\cup B) \\cap C = (A \\cap C) \\cup (B \\cap C), \\quad\n(A \\cap B) \\cup C = (A \\cup C) \\cap (B \\cup C)\n\\]\n\n德·摩根律：\n\\[\n\\overline{A \\cup B} = \\overline{A} \\cap \\overline{B}, \\quad\n\\overline{A \\cap B} = \\overline{A} \\cup \\overline{B}\n\\]\n\n吸收律：\n\\[\n\\text{如果 } A \\subset B, \\text{ 则 } A \\cup B = B, \\quad A \\cap B = A\n\\]\n\n## 事件的概率\n\n事件A发生的可能性大小为P(A) 称为A的概率\n\nA出现的频率 = (A出现的次数/实验总次数)\n\n### 古典概型\n\n- 实验结果为有限个\n- 各个结果发生的可能性相等\n\nP(A) =  (A出现的次数/实验总次数)\n\n### 几何概型\n\n允许实验结果为无限个\n\n### 公理化定义\n\n- 非负性 ，0 ≤ P(A) ≤ 1\n- 规范性 P（Ω） = 1\n- 完全可加性 n个事件并集概率 = n个事件加起来的概率\n\n性质：\n\n- P(∅) = 0 不可能事件概率为0\n- n个事件并集概率 = n个事件加起来的概率\n- P（A）+P(<SPAN style=\"TEXT-DECORATION: overline\">A</SPAN>）\n- P（B-A）=P(B)-P(AB)\n- P(A∪B)=P(A)+P(B)-P(AB)\n\n## 条件概率与事件的独立性\n\n### 条件概率\n\n已知事件B发生的条件下，事件A发生的可能性的客观度量称为条件概率，记为P(A|B)。也就是某个事件受其他事件影响之后出现的概率\n\nP(A|B) = P(AB) / P(B)\n\n- 乘法定理\n\nP (AB) = P(A)P(B|A)\nP (AB) = P(B)P(A|B)\n\n### 全概率公式\n\n用于多个原因导致一个结果发生\n\n有互不相容事件B1 B2 B3 BN\nB1...BN 概率和为1\nA为Ω中的一个事件\n则 A = P(AB1) + P(AB2)...\n\n### 贝叶斯公式\n\n结果为x的事件，求y导致其发生的概率\n\nP(x|y) = P(y|x)XP(x)/P(y)\n\n#### 贝叶斯原理\n\n- 先验概率：通过抽样得到的事情发生的概率\n- 后验概率：发生结果之后，推测原因的概率\n- 条件概率\n- 似然函数\n\n贝叶斯原理就是求解后验概率\n\n#### 朴素贝叶斯\n\n基于一个简单假设建立的一种贝叶斯方法，并假定数据对象的不同属性对其归类影响时是相互独立的\n\n结果为x的事件，求y，z导致其发生的概率\n\nP(x|y,z) = P(x|y) X P(x|z)\n\n在 A1、A2、A3 离散属性下，$C_j$ 的概率：\n\n$$\nP(C_j|A_1A_2A_3) = \\frac{P(A_1A_2A_3|C_j)P(C_j)}{P(A_1A_2A_3)}\n$$\n\n如果要处理连续值，则通过样本计算出均值和方差，也就是得到正态分布的密度函数转成离散值\n\n在机器学习中，通过事先对对象提取各个特征，计算可能性，再对未知对象时，通过各个特征的分值，就可以计算对象属于什么类的概率\n\nVS其他算法：\n\n- 和 KNN 最近邻相比，朴素贝叶斯需要更多的时间进行模型的训练，但是它在对新的数据进行分类预测的时候，通常效果更好、用时更短\n- 和决策树相比，朴素贝叶斯并不能提供一套易于人类理解的规则，可以提供决策树通常无法支持的模糊分类\n- 和 SVM 支持向量机相比，朴素贝叶斯无法直接支持连续值的输入\n\n朴素贝叶斯模型中的连续乘积会导致过小的值，甚至计算机都无法处理。为了避免这种情况，我们可以使用 log 的数学变换，将小数转换为绝对值大于 1 的负数\n\n文本分类：\n\n准备好各个词属于哪个分类的概率 -> 文本分词 -> 使用朴素贝叶斯计算分出的词属于哪个分类可能性最大\n\n### 事件的独立性\n\n若P(A|B) = P(A) 或 P(B|A)=P(B) 或 P(AB)=P(A)P(B)\n\n则事件A与B互相独立\n\n### 马尔可夫假设\n\n- 任何一个词 wi​ 出现的概率只和它前面的 1 个或若干个词有关\n\n> 链式法则：P(x1,x2,x3,...,xn) = P(x1) X P (x2 | x1) X P(x3 | x1, x2) X P(xn | x1,x2,...,xn-1)\n\n二元文法模型：某个单词出现的概率只和它前面的 1 个单词有关\n\nP(wn | w1,w2,...,wn-1) ≈ P(wn | wn-1)\n\n语言模型可以用来：\n\n1. 信息检索：给定一个查询，哪篇文档是更相关的\n2. 分词：可以估算出基于词典分割的方式，哪种分割最为合理\n\n#### 马尔可夫模型\n\n状态到状态之间是有关联的。前一个状态有一定的概率可以转移到到下一个状态。如果多个状态之间的随机转移满足马尔科夫假设，那么这类随机过程就是一个马尔科夫随机过程，刻画这类随机过程的统计模型，就是马尔科夫模型\n\n隐含马尔可夫模型：像在语音识别中，同样的发音可以被识别为不同的文字，那么使用隐含模型，就可以在所有可能的识别结果中，选择可能性最高的一个\n\n### 信息熵\n\n刻画给定集合的纯净度大小的一个指标，纯净度的大小与元素种类多样性成反比\n\n信息增益：对元素种类划分后，系统整体熵的下降\n\n一种决策树算法就是每次计算问题的信息熵，挑选信息增益最高的问题，也就是区分度最高的问题\n\n#### 特征选择\n\n如果一个特征，经常只在某个或少数几个分类中出现，而很少在其他分类中出现，那么说明这个特征具有较强的区分力，这个时候，对于一个特征，我们可以看看包含这个特征的数据，是不是只属于少数几个类，就可以使用信息熵来计算区分度：\n\n$$\n-\\sum_{j=1}^nP{\\left(c_j\\mid Df_i\\right)}\\times\\log_2P{\\left(c_j\\mid Df_i\\right)}\n$$\n\n另外一种方式是卡方检验来检验两个变量是否相互独立：\n\n> 如果两者独立，证明特征和分类没有明显的相关性，特征对于分类来说没有提供足够的信息量。反之，如果两者有较强的相关性，那么特征对于分类来说就是有信息量的，是个好的特征。\n\n#### 特征变化\n\n- 归一化：是获取原始数据的最大值和最小值，然后把原始值线性变换到[0,1]之间，这种方法有个不足最大值与最小值非常容易受噪音数据的影响\n\nx' = (x - min) / (max - min)\n\n- 标准化：该方法假设数据呈现标准正态分布，z 分数标准化是利用标准正态分布的特点，计算一个给定分数距离平均数有多少个标准差，不容易受到噪音影响\n\nx' = (x - 均值) / 标准差\n\n## 随机变量及其分布\n\n随机变量：对于Ω上的每一样本点w，都有一个实数与之对应，则称X(w)的X为随机变量，用来描述事件所有可能出现的状态\n\n分布函数F(x)=P(X<=x>)\n\n概率分布描述的其实就是随机变量的概率规律\n\n### 离散型随机变量\n\n有一类随机变量可能的取值是有限个或可列无穷个，称之为离散型随机变量\n\n各个可能的取值组合起来称之为随机变量X的分布律\n\n- 常用离散型分布\n  - 0-1分布、伯努利分布：单个随机变量的分布，而且这个变量的取值只有两个，0 或 1\n  - 二项分布：描述了一个具有 k 个不同状态的单个随机变量\n  - 几何分布\n  - 泊松分布\n\n### 连续型随机变量\n\n一些随机变量的可能取值可充满一个区间，称之为连续型随机变量\n\n#### 常用连续型分布\n\n- 均匀分布\n- 指数分布\n- 正态分布、高斯分布：，越靠近中心点μ，出现的概率越高，而随着渐渐远离μ，出现的概率先是加速下降，然后减速下降，直到趋近于 0\n\n### 期望值\n\n> 也叫数学期望，是每次随机结果的出现概率乘以其结果的总和\n\n## 二维随机变量及其分布\n\n对于Ω上的每一样本点w，有两个实数XY与之对应，则（X,Y）为二维随机变量\n\n- 联合分布函数\n\n### 二维离散型随机变量\n\n### 二维连续型随机变量\n\n## 统计意义\n\n> 显著性差异：研究多组数据之间的差异是由于不同的数据分布导致的呢，还是由于采样的误差导致的\n\n- 虚无假设：H0，事先对随机变量的参数或总体分布作出一个假设，然后利用样本信息来判断这个假设是否合理\n- 队里假设：H1，如果证明虚无假设不成立，那么就可以推出对立假设成立\n\nP 值：当 H0 假设为真时，样本出现的概率\n\n方差分析，也叫 F 检验。这种方法可以检验两组或者多组样本的均值是否具备显著性差异\n\n### 过拟合与欠拟合\n\n![2022118202517](/assets/2022118202517.webp)\n\n- 欠拟合问题，产生的主要原因是特征维度过少，拟合的模型不够复杂，无法满足训练样本，最终导致误差较大\n  - 通过增加更多的特征，来提升模型的复杂度，让它从欠拟合阶段往适度拟合阶段靠拢\n- 过拟合问题产生的主要原因则是特征维度过多，导致拟合的模型过于完美地符合训练样本，但是无法适应测试样本或者新的数据\n  - 剪枝：删掉决策树中一些不是很重要的结点及对应的边，这其实就是在减少特征对模型的影响\n  - 随机森林：多次从全部样本中提取一定数量构建决策树，对于新的数据，每个决策树都会有自己的判断结果，我们取大多数决策树的意见作为最终结果\n","metadata":"","hasMoreCommit":true,"totalCommits":21,"commitList":[{"date":"2025-09-16T16:38:28+08:00","author":"MY","message":"docs: 更新运算律内容","hash":"a93c2eba4ab12322425558b7d47d2cebc1dd5aec"},{"date":"2024-01-08T20:01:26+08:00","author":"MY","message":"✏机器学习","hash":"80f8b5e13efb5889c6cc6a45c7df2aa7458e2203"},{"date":"2023-04-12T17:26:39+08:00","author":"MY","message":"📦数学","hash":"790dcb8bb23f5e4890ae2dabbe484ba436c2efed"},{"date":"2023-04-10T22:17:25+08:00","author":"MY","message":"✏️概数","hash":"7b6c8f962829b9b77df1f36bb26f5b076653431b"},{"date":"2022-11-08T20:33:13+08:00","author":"cjiping","message":"✏️概数","hash":"478d4ca42794871f4362d6d5d079d2f7ca56a49d"},{"date":"2022-11-07T20:47:56+08:00","author":"MY","message":"✏️概数","hash":"8675687019104e9cb5c70740390c734398c59fb2"},{"date":"2022-11-06T20:17:07+08:00","author":"MY","message":"✏️概数","hash":"04386c1fe155962e343707009ddb787fab01aa7f"},{"date":"2022-11-02T20:47:19+08:00","author":"MY","message":"✏️概数","hash":"9e6377148b82af4622e05d52c8066bc67de536ed"},{"date":"2022-10-31T21:46:12+08:00","author":"MY","message":"✏️概数","hash":"9ada7f2a24a671eb77a9a0287ea4bcb5b1ff09be"},{"date":"2022-10-30T20:46:05+08:00","author":"MY","message":"✏️概数","hash":"b897169c5b9b9442299ccf193834a6750ec75f08"}],"createTime":"2020-06-05T11:54:28+08:00"}