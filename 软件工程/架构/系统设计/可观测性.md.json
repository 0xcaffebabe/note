{"name":"可观测性","id":"软件工程-架构-系统设计-可观测性","content":"# 可观测性\n\n## 1. 可观测性的本质与理论基础\n\n如果能够在不发布新代码（如增加一个用于调试的日志）的情况下理解任何奇怪或不确定性的状态，那么我们的系统就具备可观测性。\n\n### 1.1 可观测性的科学基础\n\n可观测性源自控制理论，其核心数学定义是：通过系统的输出（观测值）能够唯一确定系统内部状态的全部信息。在现代分布式系统中，可观测性已从纯粹的数学概念演变为工程实践，成为理解复杂系统行为的基石。\n\n### 1.2 系统复杂性与可观测性\n\n现代软件系统的复杂性呈现指数级增长：\n- **架构复杂性**：微服务、容器化、网格化部署\n- **动态复杂性**：自动化扩缩容、蓝绿部署、灰度发布\n- **交互复杂性**：多租户、API网关、异步消息传递\n\n结构化的事件（Structured Events）是可观测性的基础，通过高基数（指包含在一个集合中的唯一值的数量）、高维度（数据中键（key）的数量）的事件，将成为能够发现隐藏在复杂系统架构中的其他隐藏问题的关键组成部分。\n\n### 1.3 可观测性与传统监控的区别\n\n| 维度 | 传统监控 | 可观测性 |\n|------|----------|----------|\n| **问题发现方式** | 预定义规则与阈值告警 | 探索式发现未知问题 |\n| **关注点** | 基础设施资源状态 | 应用软件行为与用户体验 |\n| **数据广度** | 主要为指标数据 | 指标、日志、追踪、事件全覆盖 |\n| **灵活性** | 静态仪表板 | 动态查询与关联分析 |\n\n## 2. 三支柱模型深度解析\n\n以下三种监控数据都只是结构化事件的一部分\n\n| 核心维度 | 定义/特性 | 与其他维度的交集 | 交集描述 |\n| --- | --- | --- | --- |\n| **指标 (Metrics)** | **可聚合的 (Aggregatable)**：用于衡量一段时间内的数值（如 CPU 使用率、请求量）。 | 指标 + 追踪 | **请求范围内的指标 (Request-scoped metrics)**：针对特定请求路径产生的度量数据。 |\n| **追踪 (Tracing)** | **请求范围的 (Request scoped)**：记录单个请求在分布式系统中的完整生命周期。 | 追踪 + 日志 | **请求范围内的事件 (Request-scoped events)**：在特定追踪上下文中发生的详细日志事件。 |\n| **日志 (Logging)** | **事件 (Events)**：离散的、详细的记录，描述系统中发生的具体事物。 | 日志 + 指标 | **可聚合的事件 (Aggregatable events)**：例如日志汇总（rollups），将离散日志转化为计数指标。 |\n| **中心交集** | **三者结合** | 指标 + 追踪 + 日志 | **请求范围且可聚合的事件 (Request-scoped, aggregatable events)** |\n\n### 2.1 日志：系统行为的时间戳记\n\n日志记录离散事件，通过这些记录事后分析出程序的行为。现代日志系统不仅记录文本信息，还包括结构化数据、元数据和上下文信息。\n\n**日志分级策略**：\n- **DEBUG**：详细调试信息，主要用于开发阶段\n- **INFO**：一般性信息，记录系统正常运行的关键节点\n- **WARN**：潜在问题，可能需要关注但不影响系统正常运行\n- **ERROR**：错误事件，影响单个操作但系统仍可运行\n- **FATAL**：严重错误，可能导致系统崩溃\n\n**结构化日志最佳实践**：\n- 采用统一的JSON格式\n- 包含必要的上下文信息（traceId、spanId、serviceId等）\n- 遵循语义化日志标准（如OpenTelemetry日志语义约定）\n\n### 2.2 追踪：分布式系统的路径可视化\n\n单体的调用栈追踪或者服务调用之间的分布式追踪。追踪系统的核心是建立请求在分布式系统中的完整路径。\n\n**追踪数据模型**：\n- **Trace**：表示一个完整的请求路径\n- **Span**：表示一个操作单元，包含开始时间、结束时间、标签、事件等\n- **Span Context**：传递追踪上下文的载体，包含traceId和spanId\n\n**分布式追踪挑战与解决方案**：\n1. **异构技术**：通过标准化协议（如W3C Trace Context）实现跨语言、跨框架的追踪\n2. **性能敏感**：采用采样策略，在性能和可观测性之间找到平衡\n3. **对应用透明**：使用字节码插桩或eBPF等技术实现无侵入式追踪\n4. **自动扩缩容**：动态服务发现与追踪上下文传播\n5. **持续监控**：建立端到端的追踪数据处理流水线\n\n**数据收集模式对比**：\n- **基于日志**：通过日志聚合分析追踪信息，简单易实现但性能开销大\n- **基于服务**：通过代码插桩获取详细信息，但对应用有侵入性\n- **基于Sidecar**：对应用透明，但仅限服务间调用追踪\n\n#### 2.2.1 追踪规范化演进\n\nOpenTracing（链路追踪标准） -> OpenCensus（在前者的基础上，还包括度量） -> OpenTelemetry（统一标准）\n\n**OpenTelemetry关键特性**：\n- **跨语言支持**：Java、Go、Python、JavaScript、C++等主流语言\n- **自动插桩**：零代码配置实现常见框架的可观测性数据收集\n- **可扩展性**：丰富的SDK和API支持自定义数据收集和处理\n\n### 2.3 度量：系统状态的量化表达\n\n度量是指对系统中某一类信息的统计聚合。度量数据提供了系统行为的量化视图，支持趋势分析和容量规划。\n\n**指标数据类型详解**：\n\n- **计数度量器（Counter）**：单调递增或递减的累积值，适用于累计事件计数\n  - 示例：HTTP请求总数、错误计数、任务完成数\n  - 特点：只能增加（或减少），支持计数和速率计算\n\n- **瞬态度量器（Gauge）**：表示某个指标在某个时点的数值，通常关注的是当前值\n  - 示例：CPU使用率、内存占用、队列长度、温度传感器读数\n  - 特点：可以任意增减，表示瞬时状态\n\n- **吞吐率度量器（Meter）**：单位时间内某个事件的发生次数\n  - 示例：每秒请求数（RPS）、每分钟错误数、吞吐量\n  - 特点：基于Counter的衍生指标，包含移动平均\n\n- **直方图度量器（Histogram）**：描述数据分布特征，记录数值的分布情况\n  - 示例：请求响应时间分布、数据库查询时间分布\n  - 特点：可计算分位数、平均值、百分位数\n\n- **采样点分位图度量器（Quantile Summary）**：在客户端计算分位值，然后把计算之后的结果推给服务端存储\n  - 示例：p50、p95、p99响应时间分位数\n  - 特点：精确的分位数计算，但数据量较大\n\n**指标采集方式**：\n- **Push模式**：客户端主动推送数据到监控系统（如StatsD、InfluxDB Line Protocol）\n- **Pull模式**：监控系统定期从客户端拉取数据（如Prometheus）\n\n**指标传输协议**：\n- **OpenMetrics**：基于Prometheus文本格式的开放指标标准\n- **OTLP**：OpenTelemetry Protocol，支持多种数据类型的统一传输协议\n\n## 3. OpenTelemetry生态系统深度解析\n\n### 3.1 核心组件架构\n\nOpenTelemetry定义了完整的可观测性数据收集、处理和导出体系：\n\n**API（Application Programming Interface）**：定义用于生成和关联追踪、指标和日志的数据类型和操作。API是语言无关的规范，确保不同语言实现的兼容性。\n\n**SDK（Software Development Kit）**：定义API特定语言实现的要求，同时还定义配置、数据处理和导出等概念。SDK提供具体的实现和扩展点。\n\n**数据模型（Data Model）**：基于Protocol Buffers定义的通用数据模型，支持追踪、指标和日志三种信号。\n\n### 3.2 OpenTelemetry Collector架构\n\nOpenTelemetry Collector提供与供应商无关的实现，用于接收、处理和导出遥测数据。\n\n```\nReceivers → Processors → Exporters\n```\n\n**Receivers（接收器）**：\n- 支持多种数据源：OTLP、Jaeger、Zipkin、Prometheus等\n- 负责协议解析和数据格式转换\n- 提供数据验证和初步过滤功能\n\n**Processors（处理器）**：\n- 数据增强：添加环境标签、服务信息等\n- 数据转换：格式化、匿名化、采样等\n- 数据过滤：排除敏感信息或不必要的数据\n- 数据聚合：批量处理和压缩\n\n**Exporters（导出器）**：\n- 支持多种后端：Prometheus、Jaeger、Zipkin、Elasticsearch等\n- 提供数据格式转换和传输功能\n- 支持批量发送和重试机制\n\n**部署模式**：\n\n1. **Agent模式**：作为守护进程或边车（sidecar）与应用部署在一起\n   - 优势：低延迟、本地缓冲、减少网络调用\n   - 适用场景：单机部署、容器化部署\n\n2. **Gateway模式**：作为独立中间件部署，汇聚多个Agent数据\n   - 优势：集中管理、统一配置、高级处理能力\n   - 适用场景：大规模部署、多租户环境\n\n3. **混部模式**：结合Agent和Gateway的优势\n   - 优势：灵活性高、容错能力强\n   - 适用场景：复杂网络环境、混合云部署\n\n### 3.3 语义约定（Semantic Conventions）\n\nOpenTelemetry定义了标准的属性和标签约定，确保不同系统收集的可观测性数据具有统一的含义和结构：\n\n- **资源属性**：描述产生遥测数据的实体（如主机、容器、云资源）\n- **跨度属性**：描述追踪中的操作（如HTTP方法、数据库操作类型）\n- **事件属性**：描述特殊事件（如异常、业务事件）\n- **指标属性**：描述度量的维度（如服务名、操作类型）\n\n## 4. 现代可观测性技术栈\n\n### 4.1 数据收集层\n\n**应用层插桩**：\n- **自动插桩**：OpenTelemetry自动检测并注入可观测性代码\n- **手动插桩**：开发者主动添加追踪和度量点\n- **框架集成**：Spring Boot、Express.js等主流框架的可观测性支持\n\n**基础设施层收集**：\n- **系统指标**：CPU、内存、磁盘、网络等系统资源指标\n- **容器指标**：Docker、Kubernetes容器运行时指标\n- **网络指标**：服务网格（如Istio、Linkerd）网络层指标\n\n**网络层观测**：\n- **eBPF技术**：在内核层面收集网络、系统调用数据，几乎零性能开销\n- **网络流数据分析**：NetFlow、sFlow等协议分析网络流量模式\n- **包捕获与分析**：Wireshark、tcpdump等工具的自动化版本\n\n### 4.2 数据存储与查询\n\n**时序数据库优化策略**：\n\n如果使用传统的关系型数据库存储度量数据，那每天监控数据的产生量将会非常的大。大部分度量数据都可以使用专门的时序数据库来进行存储。\n\n由于度量数据多写少读、几乎不删改、数据只顺序追加这些特点，时序数据库就可以使用某些策略来进行优化：\n\n1. **日志结构的合并树（LSM-Tree）**：先写内存再批量刷盘，优化写入性能\n2. **数据采样策略**：对历史数据进行降采样，如几周前的数据只保留小时级聚合，几年前的数据只保留日级聚合\n3. **数据生命周期管理**：类似环形缓冲区，输入无限但存储有限，根据数据重要性设置不同的保留策略\n\n**主流时序数据库对比**：\n- **Prometheus**：拉模型、服务发现、强大的PromQL查询语言\n- **InfluxDB**：写入性能优异、支持SQL-like查询、丰富的生态系统\n- **TimescaleDB**：基于PostgreSQL的时序扩展，支持完整SQL功能\n- **VictoriaMetrics**：高性能、低资源消耗、兼容Prometheus生态\n\n**分布式追踪存储**：\n- **Jaeger**：支持多种存储后端（Cassandra、Elasticsearch），强大的查询功能\n- **Zipkin**：轻量级、易于部署，适合中小型系统\n- **Tempo**：Grafana Labs开发，专注于高可扩展性的分布式追踪\n\n### 4.3 数据分析与可视化\n\n**告警系统**：\n- **Grafana Alerting**：与Grafana仪表板深度集成的告警引擎\n- **AlertManager**：Prometheus生态系统中的告警管理和去重工具\n- **自定义告警平台**：基于机器学习的异常检测和智能告警\n\n**日志分析平台**：\n- **ELK Stack（Elasticsearch、Logstash、Kibana）**：成熟的企业级日志分析解决方案\n- **EFK Stack（Elasticsearch、Fluentd、Kibana）**：容器化环境下的日志收集分析\n- **Loki Stack（Loki、Promtail、Grafana）**：低存储成本的日志聚合系统\n\n## 5. 可观测性驱动开发（ODB）\n\n在整个开发过程中考虑应用程序的可靠性和软件质量，利用工具或是插桩来观测系统的状态和行为。\n\n### 5.1 开发阶段的可观测性\n\n**设计阶段**：\n- 在系统架构设计时考虑可观测性需求\n- 定义关键业务指标和SLI/SLO\n- 规划日志结构和追踪上下文\n\n**编码阶段**：\n- 遵循语义约定添加结构化日志\n- 设计关键业务路径的追踪点\n- 实现健康检查和就绪检查接口\n\n**测试阶段**：\n- 验证可观测性数据的正确性\n- 测试告警规则的有效性\n- 压力测试时的性能指标基线建立\n\n### 5.2 部署与运维阶段\n\n**部署阶段**：\n- 验证可观测性组件正确配置\n- 检查数据收集、处理、存储、可视化链路完整性\n- 建立部署相关的可观测性指标\n\n**监控阶段**：\n- 建立多层次监控体系（基础设施、平台、应用、业务）\n- 实现智能告警降噪和聚合\n- 建立基于机器学习的异常检测机制\n\n**故障响应阶段**：\n- 利用追踪数据快速定位故障点\n- 通过日志关联分析根本原因\n- 基于指标数据评估故障影响范围\n\n## 6. 可观测性文化与组织能力建设\n\n### 6.1 文化变革理念\n\n**拥抱失败**：\n- 将故障视为学习和改进的机会\n- 建立无指责的故障复盘文化\n- 鼓励快速实验和快速失败\n\n**允许犯错**：\n- 事件后审查的目标应该是识别系统和流程中的弱点，并通过建立可观测性和工程化来避免这个错误再次发生\n- 建立安全的心理环境，让工程师敢于报告问题\n- 实施\"事后分析\"（Post-Mortem）流程，而非\"事前审批\"流程\n\n**拒绝个人英雄主义**：\n- 依靠系统和流程而非少数人的能力来理解和调试系统\n- 建立共享的可观测性平台和知识库\n- 实施团队轮值on-call，避免知识孤岛\n\n**早排查**：\n- 代码部署到生产环境后，应及时通过可观测性来查看生产环境的状态\n- 建立自动化测试和部署流水线\n- 实施\"左移\"策略，在开发阶段就建立可观测性\n\n### 6.2 组织能力建设\n\n**SRE（Site Reliability Engineering）实践**：\n- 建立服务水平指标（SLI）和服务水平目标（SLO）\n- 实施错误预算管理\n- 推行混沌工程实践\n\n**DevOps文化融合**：\n- 促进开发与运维团队之间的协作\n- 共同承担系统可靠性的责任\n- 建立统一的可观测性语言和框架\n\n**知识管理与传承**：\n- 建立故障知识库和经验文档\n- 定期进行可观测性培训和最佳实践分享\n- 建立跨团队的可观测性治理机制\n\n## 7. 可观测性成熟度框架\n\n### 7.1 成熟度阶段定义\n\n**阶段1：被动感知（Reactive Awareness）**\n- 能力特征：系统出问题后才能感知到\n- 主要痛点：故障响应时间长，缺乏故障预防能力\n- 关键指标：MTTR（平均修复时间）较长，MTBF（平均故障间隔时间）不稳定\n- 技术栈：基础监控告警，简单日志收集\n\n**阶段2：快速响应（Rapid Response）**\n- 能力特征：快速了解问题的背景和影响，此时回滚是第一位的\n- 关键改进：建立了标准化的告警和响应流程\n- 关键指标：MTTR显著降低，故障恢复时间可预测\n- 技术栈：三支柱模型，统一的可观测性平台\n\n**阶段3：主动预防（Proactive Prevention）**\n- 能力特征：问题被修复之后，此时工程师可以花时间定位和理解潜在问题\n- 关键改进：具备故障预测和异常检测能力\n- 关键指标：MTBF显著提升，故障发生频率降低\n- 技术栈：机器学习驱动的异常检测，混沌工程\n\n**阶段4：持续优化（Continuous Optimization）**\n- 能力特征：基于可观测性数据持续改进系统架构和性能\n- 关键改进：建立数据驱动的决策机制\n- 关键指标：业务指标与技术指标关联，系统性能持续提升\n- 技术栈：A/B测试、功能开关、性能基准测试\n\n**阶段5：认知增强（Cognitive Enhancement）**\n- 能力特征：系统具备自我感知、自我修复能力\n- 关键改进：AI驱动的自动化故障处理\n- 关键指标：大部分故障自动修复，人工干预仅处理复杂场景\n- 技术栈：AIOps、自动化编排、智能运维\n\n### 7.2 成熟度衡量指标体系\n\n**技术维度指标**：\n- 数据覆盖率：系统组件的可观测性覆盖比例\n- 数据时效性：从事件发生到数据可视化的延迟\n- 数据准确性：错误数据和噪声数据的比例\n- 查询响应时间：复杂查询的平均响应时间\n\n**业务维度指标**：\n- 用户体验指标：页面加载时间、API响应时间、错误率\n- 业务连续性：系统可用时间比例、业务中断影响\n- 服务品质：SLI达成率、SLO符合度\n\n**组织维度指标**：\n- 故障响应时间：从告警到响应的平均时间\n- 知识共享度：团队间知识文档的完善程度\n- 技能水平：团队成员可观测性技能评估\n\n## 8. 最佳实践与实施路径\n\n### 8.1 实施策略\n\n**渐进式部署**：\n1. 从核心业务系统开始试点\n2. 逐步扩展到整个系统架构\n3. 建立标准化的部署和配置模板\n\n**标准化建设**：\n- 制定统一的日志格式和追踪规范\n- 建立标准的服务等级指标（SLI）\n- 设计通用的仪表板模板\n\n**治理机制**：\n- 建立可观测性数据的治理流程\n- 实施数据保留和归档策略\n- 建立跨团队的协调机制\n\n### 8.2 挑战与解决方案\n\n**性能挑战**：\n- 问题：大量可观测性数据对系统性能的影响\n- 解决方案：采用异步收集、批量传输、智能采样等技术\n\n**数据量挑战**：\n- 问题：海量可观测性数据的存储和处理成本\n- 解决方案：数据分级存储、冷热数据分离、数据压缩\n\n**复杂性挑战**：\n- 问题：分布式系统可观测性数据的关联分析困难\n- 解决方案：建立统一的ID体系、上下文传播机制\n\n## 9. 未来发展趋势\n\n### 9.1 技术演进方向\n\n**AI与可观测性融合**：\n- 机器学习驱动的异常检测\n- 自动根因分析\n- 预测性运维\n\n**边缘计算可观测性**：\n- 分布式边缘节点的统一可观测性\n- 网络分区情况下的数据收集策略\n- 边缘设备的轻量级可观测性方案\n\n**零信任架构下的可观测性**：\n- 数据加密传输和存储\n- 细粒度的访问控制和审计\n- 隐私保护的数据收集策略\n\n### 9.2 行业标准化\n\n- OpenTelemetry成为行业标准\n- W3C Trace Context协议的普及\n- 云原生可观测性标准的建立\n\n日志收集：与具体技术栈无关 ELK EFK\n\n度量：Prometheus\n\n链路追踪：Zipkin...\n\n健康检查API模式：\n\n![屏幕截图 2021-01-29 094428](/assets/屏幕截图%202021-01-29%20094428.png)\n\n### Prometheus\n\n![架构](/assets/批注%202020-04-22%20150857.png)\n\n- Receiver：负责按照对应的协议格式监听和接收遥测数据，并把数据转给一个或者多个 Processor。\n- Processor：负责加工处理遥测数据，如丢弃数据、增加信息、转批处理等，并把数据传递给下一个 Processor 或者一个或多个 Exporter。\n- Exporter：负责把数据发送给下一个接收端（一般是指后端），比如将指标数据存储到 Prometheus 中\n\n部署模式：\n\n1. Agent模式 通过边车直接跟应用部署在一起\n2. Gatewaay模式，一个独立的中间件，\n\n### 存储查询\n\n如果使用传统的关系型数据库存储度量数据 那每天监控数据的产生量将会非常的大\n\n大部分度量数据都可以使用专门的时序数据库来进行存储\n\n由于度量数据多写少读、几乎不删改、数据只顺序追加这些特点，时序数据库就可以使用某些策略来进行优化：\n\n1. 日志结构的合并树\n2. 对数据进行采样进行节省空间 比如几周前的数据就只保留一天 几年前的就保留一周\n3. 轮替数据存储 类似于环形缓冲区 输入可以无限 存储有限\n\n### 监控预警\n\n- Grafana\n- Alter Manager\n\n## 可观测性驱动开发\n\n在整个开发过程中考虑应用程序的可靠性和软件质量，利用工具或是插桩来观测系统的状态和行为\n\n### 文化\n\n- 拥抱失败\n- 允许犯错：事件后审查的目标应该是识别系统和流程中的弱点，并通过建立可观测性和工程化来避免这个错误再次发生\n- 拒绝个人英雄主义：依靠少数人甚至一个人的能力来理解和调试系统是不可信的\n- 早排查：代码部署到生产环境后，应及时通过可观测性来查看生产环境的状态\n\n## 可观测性文化\n\n1. 用真实数据确定工作优先级并做出决策\n2. 根据对业务来说真正重要的事情发出告警，找出真正的问题或是影响，而不仅仅根据基础架构的情况作出判断\n3. 不断消除告警\n4. 持续地对文档进行改进对于建立可观测性文化来说至关重要\n\n## 可观测性成熟度框架\n\n- 阶段1：感知到问题\n- 阶段2：快速了解问题的背景和影响，此时回滚是第一位的\n- 阶段3：问题被修复之后，此时工程师可以花时间定位和理解潜在问题\n\n## 关联文档\n\n- [/软件工程/架构/系统设计/监控系统设计.md](/软件工程/架构/系统设计/监控系统设计.md) - 监控系统设计从目标、架构、指标维度等方面系统阐述了现代监控体系的构建方法，与可观测性在数据收集、分析、告警等方面有密切关联\n- [/软件工程/架构/系统设计/日志.md](/软件工程/架构/系统设计/日志.md) - 日志是可观测性三支柱之一，该文档从日志规范、实现、使用等方面详细阐述了结构化日志的设计与实践\n- [/软件工程/架构/系统设计/前端监控.md](/软件工程/架构/系统设计/前端监控.md) - 前端监控是可观测性在客户端的重要延伸，涵盖了前端性能指标、异常监控、用户行为追踪等关键内容\n- [/运维/运维.md](/运维/运维.md) - 运维体系涵盖了可观测性在现代运维中的应用，包括CMDB、监控告警、自愈系统等运维知识模型\n- [/操作系统/容器化.md](/操作系统/容器化.md) - 容器化技术是可观测性在云原生环境下实施的基础，涉及容器监控、资源限制、命名空间等概念\n- [/软件工程/DevOps.md](/软件工程/DevOps.md) - DevOps实践与可观测性密切相关，特别是在CI/CD流水线中集成监控告警、自动化测试等可观测性实践\n- [/数据技术/数据处理.md](/数据技术/数据处理.md) - 大数据处理平台的可观测性涉及海量数据的采集、存储、分析和可视化，是可观测性在数据领域的应用扩展","metadata":"tags: ['运维']","hasMoreCommit":true,"totalCommits":13,"commitList":[{"date":"2026-02-12T14:07:03+08:00","author":"MY","message":"doc: 整理标签","hash":"290b3e8ad18f48832ac282290238d020fc030a88"},{"date":"2026-01-21T14:15:15+08:00","author":"MY","message":"docs(observability): 将监控图表替换为表格形式并更新可观测性内容","hash":"8220d01b52ca5f596d91ce19b1dba6f9162648c6"},{"date":"2025-12-01T14:52:15+08:00","author":"MY","message":"docs(微服务): 删除服务监控文档并更新相关引用","hash":"642172996d1e1c114a8d7ef92b454749e7b49c95"},{"date":"2025-11-16T21:30:56+08:00","author":"MY","message":"docs: 统一并精简文档标签","hash":"21362e9d7aeb62e05364cd5e7f3a3c24d7e293c7"},{"date":"2025-11-13T19:32:06+08:00","author":"MY","message":"docs(可观测性): 完善可观测性系统设计文档","hash":"4c21dbb1de570b2e22123017dc14e05708604019"},{"date":"2024-05-28T19:53:40+08:00","author":"MY","message":"✏监控","hash":"86620b7aeaf14cd9f9f392c4fc8ee5a3f9be003c"},{"date":"2023-09-18T17:03:32+08:00","author":"MY","message":"📦日志","hash":"e78cec26d3d3c8f6c8cfa91a61617966a1a32326"},{"date":"2022-11-25T14:57:32+08:00","author":"cjiping","message":"✏️可观测性","hash":"3b22d406a46507c4c1e658c44b223382a894b742"},{"date":"2022-11-24T15:08:54+08:00","author":"cjiping","message":"✏️可观测性","hash":"5a5ddf7570e4f994f1260e303222b9c22fac50b5"},{"date":"2022-11-23T15:05:28+08:00","author":"cjiping","message":"✏️可观测性","hash":"bcc578cee95e84d2c73cf198eb4705ef3f3b8278"}],"createTime":"2020-11-25T15:49:46+08:00"}