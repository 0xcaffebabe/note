{"name":"缓存","id":"软件工程-架构-系统设计-缓存","content":"# 缓存\n\n## 为什么使用\n\n收益：\n\n- 加速读写：缓存通常都是全内存的（缓解IO压力）\n- 降低后端负载：帮助后端减少访问量和复杂计算（缓解CPU压力）\n\n成本：\n\n- 数据不一致性：缓存层和存储层的数据存在着一定时间窗口的不一致\n- 代码维护成本：加入缓存后，需要同时处理缓存层和存储层的逻辑\n- 运维成本：如Redis集群的加入 运维会更有难度\n\n## 缓存方案设计考虑点\n\n1. 什么数据应该缓存\n2. 什么时机触发缓存和以及触发方式是什么\n3. 缓存的层次和粒度（ 网关缓存如 nginx，本地缓存如单机文件，分布式缓存如redis cluster，进程内缓存如全局变量）\n4. 缓存的命名规则和失效规则\n5. 缓存的监控指标和故障应对方案\n6. 可视化缓存数据如 redis 具体 key 内容和大小\n\n### 数据特征对缓存设计的影响\n\n- 不变性数据：优先考虑使用缓存的数据类型，不变性意味着实现一致性会非常容易\n- 弱一致性数据：对一致性的要求比较低，只要能保证最终一致性就行\n- 强一致性数据：这类数据在使用缓存时会比较复杂，而且很容易会引入新的问题\n\n## 特征\n\n性能评估模型：$$AMAT = Thit + MR * MP$$\n\n- AMAT（Average Memory Access Time），代表的是平均内存访问时间\n- Thit，是指命中缓存之后的数据访问时间\n- MR，是指访问缓存的失效率\n- MP，是指缓存失效后，系统访问缓存的时间与访问原始数据请求的时间之和\n\n### 吞吐量\n\n使用OPS值（每秒操作数，Operations per Second，ops/s）来衡量，反映了对缓存进行并发读、写操作的效率\n\n在并发读写的场景下， 避免竞争是最关键的\n\n### 命中率\n\n某个请求能够通过访问缓存而得到响应时，称为缓存命中率\n\n缓存命中率越高，缓存的利用率也就越高\n\n### 最大空间\n\n缓存的利用空间是有限的\n\n当缓存存放的数据量超过最大空间时，就需要淘汰部分数据来存放新到达的数据\n\n### 分布式支持\n\n缓存可分为“进程内缓存”和“分布式缓存”两大类\n\n- 复制式缓存：每个节点里面都存在有一份副本，读取数据时无需网络访问，直接从当前节点的进程内存中返回，当数据发生变化时，就必须遵循复制协议，将变更同步到集群的每个节点中，这种复制性能随着节点的增加呈现平方级下降，变更数据的代价十分高昂\n- 集中式缓存：是目前分布式缓存的主流形式，集中式缓存的读、写都需要网络访问，其好处是不会随着集群节点数量的增加而产生额外的负担，其坏处自然是读、写都不再可能达到进程内缓存那样的高性能。由于对象更新一个字段可能也会导致整个对象的序列化传输，所以集中式缓存更提倡缓存原始类型\n\n使用多级缓存同时得到两种类型的优点：\n\n```mermaid\nsequenceDiagram\n    participant A as 应用程序\n    participant B as 进程内缓存 (Caffeine)\n    participant C as 分布式缓存 (Redis)\n    participant D as 数据源\n\n    A ->> B: 一级缓存查询\n    alt 缓存命中\n        B ->> A: 返回数据\n    else 缓存未命中\n        A ->> C: 二级缓存查询\n        alt 缓存命中\n            C ->> A: 返回数据\n            A ->> B: 回填数据\n        else 缓存未命中\n            A ->> D: 数据源查询\n            D ->> A: 返回数据\n            A ->> C: 回填数据\n            A ->> B: 回填数据\n        end\n    end\n\n```\n\n在JVM进程内一级的缓存若过大 可能会造成GC压力过大 此时使用堆外内存分配能有效提升性能\n\n#### 集中式缓存高可用\n\n1. 客户端方案：在客户端完成缓存分片、负载均衡等操作\n2. 中间代理层：读写请求都是经过代理层完成的。代理层是无状态的，主要负责读写请求的路由功能，并且在其中内置了一些高可用扩展，Facebook 的Mcrouter，Twitter 的Twemproxy，豌豆荚的Codis\n3. 服务端方案：一般就是缓存中间件自带的，[Redis的哨兵](/中间件/数据库/redis/哨兵.md)，[Redis的集群](/中间件/数据库/redis/集群.md)\n\n### 扩展功能\n\n#### 更新策略\n\n当缓存使用量超过了预设的最大值时候 FIFO（先进先出）  LRU（最久未使用） LFU（最少使用） 等算法用来剔除部分数据 数据一致性最差（因为数据的过期完全取决于缓存） 但基本没有维护成本\n\n针对LRU的一些缺点，出现了一些算法，这些算法在某些条件下往往有更好的表现：\n\n- TinyLFU：会用少量的样本数据来估计全体数据的特征，并且每隔一段时间，便会把计数器的数值减半，以此解决“旧热点”数据难以清除的问题\n- W-TinyLFU：用来解决TinyLFU无法应对稀疏突发访问的问题\n\n超时剔除通过给缓存数据设置过期时间，让其在过期时间后自动删除 段时间窗口内（取决于过期时间长短）存在一致性问题 维护成本不高 只需要设置一个过期时间\n\n应用方对于数据的一致性要求高，需要在真实数据更新后，立即主动更新缓存数据 一致性很高 但是维护成本也是最高的\n\n#### 缓存粒度\n\n究竟是缓存全部属性还是只缓存部分重要属性呢 从三个维度判断：\n\n- 通用性：缓存全部数据比部分数据更加通用 但是数据具有热点 一般只有几个属性用的比较多\n- 空间带宽。缓存全部数据要比部分数据占用更多的空间及带宽\n- 代码维护：部分数据一旦要加新字段需要修改业务代码\n\n## 位置\n\n- 浏览器缓存\n- CDN\n- ISP缓存\n  - ISP是网络访问的第一跳，这个地方有缓存能大大加快用户的访问速度\n- 反向代理缓存\n- 本地缓存\n  - 这里指的是将缓存存放在服务器进程内\n- 分布式缓存\n  - 使用专门的服务器集群来存放缓存\n- 数据库缓存\n  - 一般数据库都有自己的缓存机制\n- CPU缓存\n\n## 读写策略\n\n### 旁路\n\n```mermaid\nsequenceDiagram\n  客户端 ->> 数据库: 更新数据库\n  客户端 ->> 缓存: 删除缓存\n  客户端 ->> 缓存: 查询缓存未命中\n  opt 异步\n    客户端 ->> 数据库: 查询数据库\n    客户端 ->> 缓存: 回写缓存\n  end\n```\n\n### 读穿写穿\n\n```mermaid\nflowchart TB\n  请求 --> 写请求\n  写请求 --> |是| 写缓存命中\n  写缓存命中 --> |是| 写缓存\n  写缓存命中 --> |否| 写数据库\n  写缓存 --> 写数据库\n  写请求 --> |否| 读缓存命中\n  读缓存命中 --> |是| 返回数据\n  读缓存命中 --> |否| 数据库加载数据到缓存\n  数据库加载数据到缓存 --> 返回数据\n```\n\n### 写回\n\n在写入数据时只写入缓存，并且把缓存块标记为“脏”的。而脏块只有被再次使用时才会将其中的数据写入到后端存储中\n\n这种策略不能被应用到常用的数据库和缓存的场景中，主要是因为一旦缓存机器掉电，就会造成原本缓存中的脏块数据丢失，是底层中如磁盘或者页缓存使用的\n\n## 缓存风险\n\n### 缓存雪崩\n\n在高并发的情况下，由于于数据没有被缓存中或者缓存都采用了相同的过期时间，导致缓存在某一时刻同时失效，请求全部发到数据库，数据库瞬时压力过重\n\n解决方案：\n\n- 锁\n  - 比如对某个key只允许一个线程数据库查询数据和写缓存，其他线程等待。但是这样就只能限制同一时间只能有一个线程访问数据库，吞吐量还是不行\n- 消息中间件\n  - 缓存中间件没有命中的情况下，生产者将缓存更新请求通过MQ发送给消费者，消费者通过自身的串行处理可以实现对缓存只写一次，后续的请求可以忽略掉\n- 使用多级缓存以及分布式缓存\n- 分析用户的行为，尽量让缓存失效的时间均匀分布（将过期时间上下浮动一定范围）\n- 缓存预热：对于可预见的热点数据 进行缓存预先加载 避免突发大流量压垮数据库\n\n概括：\n\n- 保证缓存层服务的高可用\n- 对后端服务进行限流降级 一旦后端服务不可用 直接降级返回一个友好结果\n\n### 热点key\n\n- 也叫做缓存击穿\n\n对于一些设置了过期时间的key，如果这些key可能会在某些时间点被超高并发地访问，是一种非常“热点”的数据。这个时候，需要考虑一个问题：缓存被“击穿”的问题：\n\n如果这个key的计算不能在短时间完成，那么在这个 key 在效的瞬间，大量的请求就击穿了缓存，直接请求数据库，就像是在一道屏障上凿开了一个洞\n\n解决方案：\n\n- 锁\n  - 在重建缓存时 只允许一个线程重建 其他线程必须等待\n- 不设置过期时间，而将过期时间设置在数据中，如果检测到数据过期了，再清除掉 或者当发现超过逻辑过期时间后，会使用单独的线程去构建缓存\n- 读写分离 使用 CDC 中间件从数据库同步数据到缓存\n\n### 缓存穿透\n\n指用户查询数据，在数据库没有，自然在缓存中也不会有。这样就导致用户查询的时候，在缓存中找不到，请求穿透到了数据库，然后返回空。这样就会导致每次查询不存在的数据都会绕过缓存去查询数据库\n\n解决:\n\n1. 把空结果，也给缓存起来，这样下次同样的请求就可以直接返回空了，即可以避免当查询的值为空时引起的缓存穿透。这种方案对空值做了缓存，意味着缓存层中存了更多的键，需要更多的内存空间 同时也会有一定的数据不一致性\n2. 也可以使用布隆过滤器直接对这类请求进行过滤。这种方法适用于数据命中不高、数据相对固定、实时性低（通常是数据集较大）的应用场景\n\n### 缓存一致性\n\n缓存中的数据与真实数据源中的数据不一致的现象\n\n解决：\n\n- 当数据更新的同时立即去更新缓存。将读请求和写请求串行化\n- 读缓存之前判断缓存是否是最新，否则先进行更新缓存\n- 更新数据时，先更新数据库，再删除缓存（旁路写策略）。为什么要删除缓存，而非更新缓存，如果缓存采用更新的方式，可能这个缓存压根就不会被用到，应该是用到缓存才去写入缓存\n\n保证缓存一致性需要付出很大的代价，缓存数据最好是那些对一致性要求不高的数据，允许缓存数据存在一些脏数据。或者直接使用 CDC 同步的方式，直接同步数据库，这样不仅能解耦业务代码，也能拥有最终一致性\n\n### 缓存无底洞\n\n随着缓存节点数目的增加，键值分布到更多的节点上，导致客户端一次批量操作会涉及多次网络操作\n\n解决：\n\n- 优化细粒度的远程调用\n- 减少网络通信次数\n- 使用长连接或者连接池\n\n方案|优点|缺点|网络IO\n-|-|-|-\n串行命令|编程简单，如果少量keys,性能可以满足要求|大量keys请求延迟严重|O(keys)\n串行IO|编程简单，少量节点时性能满足要求|大量node延迟严重|O(nodes)\n并行IO|延迟取决于最慢的节点|编程复杂|O(max_slow(nodes))\nhash_tag|性能最高|维护成本高,容易出现数据倾斜|O(1)\n\n## 客户端缓存\n\n### [浏览器缓存](/计算机网络/http/HTTP.md#缓存)\n\n### 应用缓存\n\n分为手机APP和Client以及是否遵循http协议\n\n在没有联网的状态下可以展示数据\n\n流量消耗过多\n\n- 漂亮的加载过程\n- 提前下发  避免秒杀时同时下发数据造成流量短时间暴增\n- 兜底数据 在服务器崩溃和网络不可用的时候展示\n- 临时缓存  退出即清理\n- 固定缓存  展示框架这种，可能很长时间不会更新，可以随客户端下发\n- 父子连接 页面跳转时有一部分内容不需要重新加载，可用从父菜单带过来\n- 预加载     某些逻辑可用判定用户接下来的操作，那么可用异步加载那些资源\n- 异步加载 先展示框架，然后异步加载内容，避免主线程阻塞\n\n## 静态化\n\n### 全量静态化\n\n将网站的所有页面预先生成静态页面，对于小型网站，页面不多，可以采用这个方式\n\n```mermaid\ngraph TD\n    A[浏览电商网站] -->|请求| B[Nginx]\n    B -->|响应|A\n    C[预先静态化好的页面] -->|html| B\n    D[MySQL] --> E[页面静态化系统]\n    E -->|html| C\n```\n\n### 按需静态化\n\n当数据发生变更，往MQ推送一条消息，消费者消费数据并进行渲染\n\n```mermaid\ngraph TD\n    客户 --> |请求|nginx\n    nginx --> |html|客户\n    nginx --> F\n    F[redis 分布式缓存] --> G[缓存服务]\n    H[MQ]\n    H --> G\n    I[商品服务信息] --> |变更消息| H\n    J[店铺服务信息] --> |变更消息| H\n    K[广告服务信息] --> |变更消息| H\n    G --> |调用接口获取变更后的数据| I\n```\n\n### 优化策略\n\n1. 增量更新：只更新发生变化的页面，减少全量更新的开销。\n2. 分片静态化：将页面划分为多个部分，分别进行静态化，提高更新效率。\n3. 批量更新：将多次数据变更合并为一次静态化操作，减少频繁更新的成本\n\n### 运维监控\n\n1. 页面生成时间\n2. 缓存命中率\n","metadata":"tags: ['架构', '系统设计']","hasMoreCommit":true,"totalCommits":20,"commitList":[{"date":"2024-11-21T19:38:10+08:00","author":"MY","message":"📦流控 & 缓存","hash":"ec18717ffca6c3c8867ce0cf6bbbeff241c19ff8"},{"date":"2024-06-03T20:02:39+08:00","author":"MY","message":"✏缓存","hash":"3b9168ab8e255e7336587bbbcccb572147314bfb"},{"date":"2024-02-27T20:07:27+08:00","author":"MY","message":"✏算法","hash":"8a6529c0b37f98855cb1857f560564cc6401fd7b"},{"date":"2023-11-22T20:09:44+08:00","author":"MY","message":"✏缓存","hash":"b38350d2024c1b603465e19f3a27f46c57eefa3f"},{"date":"2023-07-04T20:17:01+08:00","author":"MY","message":"✏缓存","hash":"0f48db6ff9abf11cb30d7c12cf1ae1d67cd547a1"},{"date":"2023-03-13T17:28:57+08:00","author":"MY","message":"📦缓存","hash":"966c5cb668266537143d43d91fdb4ba352a79bfd"},{"date":"2022-08-17T21:07:48+08:00","author":"MY","message":"✏️缓存","hash":"89b3b4c117ed92558066a535ee9719d28af1676d"},{"date":"2022-08-15T21:13:30+08:00","author":"MY","message":"✏️缓存","hash":"2b9050506928eabbe9e6a1760f4baaef4ad68147"},{"date":"2022-07-12T14:52:02+08:00","author":"cjiping","message":"✏️更新 位图与布隆过滤器","hash":"364b69c73f3ae263704ae70cbde2e602e593d0f5"},{"date":"2022-07-11T15:08:47+08:00","author":"cjiping","message":"✏️更新 分布式算法","hash":"724e42379b37f932d2d165bef4d67df2be095cb4"}],"createTime":"2020-03-17T15:36:37+08:00"}